{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: KERAS_BACKEND=tensorflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%env KERAS_BACKEND tensorflow\n",
    "import keras\n",
    "from keras.datasets import reuters\n",
    "from keras.layers import Activation, Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_words = 2048\n",
    "batch_size = 64\n",
    "epochs = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data ...\n",
      "train sequences: 7859; test sequences: 3369\n",
      "classes: 46\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('loading data ...')\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words = max_words, test_split = 0.3)\n",
    "print('train sequences: %d; test sequences: %d' % (len(x_train), len(x_test)))\n",
    "num_classes = numpy.max(y_train) + 1\n",
    "print('classes: %d\\n' % (num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train shape: (7859,); x test shape: (3369,)\n",
      "x train head: [1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 2, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 2, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n",
      "x test head: [1, 275, 492, 26, 14, 492, 26, 384, 219, 93, 102, 146, 94, 321, 17, 12]\n",
      "y train shape: (7859,); y test shape: (3369,)\n",
      "y train head: [3 4 3]\n",
      "y test head: [3 3 9]\n"
     ]
    }
   ],
   "source": [
    "print('x train shape: %s; x test shape: %s' % (x_train.shape, x_test.shape))\n",
    "print('x train head: %s' % (x_train[0]))\n",
    "print('x test head: %s' % (x_test[0]))\n",
    "print('y train shape: %s; y test shape: %s' % (y_train.shape, y_test.shape))\n",
    "print('y train head: %s' % (y_train[ : 3]))\n",
    "print('y test head: %s' % (y_test[ : 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorizing sequence data ...\n",
      "x train shape: (7859, 2048); x test shape: (3369, 2048)\n",
      "x train head: [ 0.  1.  1. ...,  0.  0.  0.]\n",
      "x test head: [ 0.  1.  0. ...,  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print('vectorizing sequence data ...')\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "x_train = tokenizer.sequences_to_matrix(x_train, mode = 'binary')\n",
    "x_test = tokenizer.sequences_to_matrix(x_test, mode = 'binary')\n",
    "print('x train shape: %s; x test shape: %s' % (x_train.shape, x_test.shape))\n",
    "print('x train head: %s' % (x_train[0, : ]))\n",
    "print('x test head: %s' % (x_test[0, : ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting class vector to binary class matrix ...\n",
      "y train shape: (7859, 46); y test shape: (3369, 46)\n",
      "y train head: [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "y test head: [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print('converting class vector to binary class matrix ...')\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print('y train shape: %s; y test shape: %s' % (y_train.shape, y_test.shape))\n",
    "print('y train head: %s' % (y_train[0, : ]))\n",
    "print('y test head: %s' % (y_test[0, : ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making model ...\n"
     ]
    }
   ],
   "source": [
    "print('making model ...')\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape = (max_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training ...\n",
      "Train on 7073 samples, validate on 786 samples\n",
      "Epoch 1/8\n",
      "7073/7073 [==============================] - 5s - loss: 1.5917 - acc: 0.6484 - val_loss: 0.9832 - val_acc: 0.7850\n",
      "Epoch 2/8\n",
      "7073/7073 [==============================] - 5s - loss: 0.7950 - acc: 0.8248 - val_loss: 0.8159 - val_acc: 0.8079\n",
      "Epoch 3/8\n",
      "7073/7073 [==============================] - 5s - loss: 0.5102 - acc: 0.8841 - val_loss: 0.7762 - val_acc: 0.8079\n",
      "Epoch 4/8\n",
      "7073/7073 [==============================] - 5s - loss: 0.3544 - acc: 0.9181 - val_loss: 0.7356 - val_acc: 0.8219\n",
      "Epoch 5/8\n",
      "7073/7073 [==============================] - 5s - loss: 0.2699 - acc: 0.9379 - val_loss: 0.7546 - val_acc: 0.8244\n",
      "Epoch 6/8\n",
      "7073/7073 [==============================] - 5s - loss: 0.2200 - acc: 0.9475 - val_loss: 0.7647 - val_acc: 0.8282\n",
      "Epoch 7/8\n",
      "7073/7073 [==============================] - 5s - loss: 0.1894 - acc: 0.9529 - val_loss: 0.8041 - val_acc: 0.8308\n",
      "Epoch 8/8\n",
      "7073/7073 [==============================] - 5s - loss: 0.1690 - acc: 0.9546 - val_loss: 0.8135 - val_acc: 0.8232\n"
     ]
    }
   ],
   "source": [
    "print('training ...')\n",
    "history = model.fit(x_train, y_train, batch_size = batch_size, epochs = epochs, verbose = 1, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating ...\n",
      "3200/3369 [===========================>..] - ETA: 0s('score:', 0.91550406637585247)\n",
      "('accuracy:', 0.80617393878349108)\n"
     ]
    }
   ],
   "source": [
    "print('evaluating ...')\n",
    "score = model.evaluate(x_test, y_test, batch_size = batch_size, verbose = 1)\n",
    "print('score:', score[0])\n",
    "print('accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
